{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/furkansaygili6/SchedulerVirtualAssistant/blob/main/planlama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ehqz_hufTG7",
        "outputId": "5ec1268f-43a9-4d56-8a90-cfd64e6a4f06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.1)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.1)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "ERROR: unknown command \"intsall\" - maybe you meant \"install\"\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.30.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.5.40)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.40)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets evaluate transformers rouge_score\n",
        "!pip intsall accelerate\n",
        "!pip install transformers[torch]\n",
        "!pip install accelerate -U\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0k7mAezfa3_",
        "outputId": "b3a08554-c22a-413c-ff78-cccfb65463f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5ZJkEP9fcj0",
        "outputId": "b6b650a6-fc4a-4c67-8a8c-6737ac6ac347"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                   Kullanıcı Girdisi  \\\n",
            "0  15:00 ile 17:00 arasında araştırma yapacağım, ...   \n",
            "1  12:00 ile 13:00 arasında öğle yemeği yapacağım...   \n",
            "2  08:00 ile 10:00 arasında ders yapacağım, 12:00...   \n",
            "3  08:00 ile 10:00 arasında ders yapacağım, 10:00...   \n",
            "4  08:00 ile 10:00 arasında ders yapacağım, 10:00...   \n",
            "\n",
            "                                            Görevler  \\\n",
            "0  15:00 - 17:00 araştırma, 17:00 - 18:00 spor, 1...   \n",
            "1  12:00 - 13:00 öğle yemeği, 13:00 - 15:00 ders,...   \n",
            "2  08:00 - 10:00 ders, 12:00 - 13:00 öğle yemeği,...   \n",
            "3  08:00 - 10:00 ders, 10:00 - 12:00 ders, 13:00 ...   \n",
            "4  08:00 - 10:00 ders, 10:00 - 12:00 ders, 18:00 ...   \n",
            "\n",
            "                                          input_text  \\\n",
            "0  15:00 ile 17:00 arasında araştırma yapacağım, ...   \n",
            "1  12:00 ile 13:00 arasında öğle yemeği yapacağım...   \n",
            "2  08:00 ile 10:00 arasında ders yapacağım, 12:00...   \n",
            "3  08:00 ile 10:00 arasında ders yapacağım, 10:00...   \n",
            "4  08:00 ile 10:00 arasında ders yapacağım, 10:00...   \n",
            "\n",
            "                                         output_text  \n",
            "0  15:00 - 17:00 araştırma, 17:00 - 18:00 spor, 1...  \n",
            "1  12:00 - 13:00 öğle yemeği, 13:00 - 15:00 ders,...  \n",
            "2  08:00 - 10:00 ders, 12:00 - 13:00 öğle yemeği,...  \n",
            "3  08:00 - 10:00 ders, 10:00 - 12:00 ders, 13:00 ...  \n",
            "4  08:00 - 10:00 ders, 10:00 - 12:00 ders, 18:00 ...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
        "import evaluate\n",
        "import re\n",
        "\n",
        "# Veri yolunu güncelleyin\n",
        "data_path = \"/content/drive/MyDrive/planlama/final_daily_life_schedules.csv\"\n",
        "\n",
        "# Veriyi yükleme\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Veri temizliği ve ön işleme fonksiyonu\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Küçük harfe çevirme\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Gereksiz boşlukları kaldırma\n",
        "    text = re.sub(r'\\s*,\\s*', ', ', text)  # Virgüller arasında doğru boşluklar\n",
        "    text = text.strip()  # Başındaki ve sonundaki boşlukları kaldırma\n",
        "    return text\n",
        "\n",
        "# Giriş ve çıkış verilerini temizleme\n",
        "df['input_text'] = df['Kullanıcı Girdisi'].apply(preprocess_text)\n",
        "df['output_text'] = df['Görevler'].apply(preprocess_text)\n",
        "\n",
        "# Temizlenmiş verileri kontrol etme\n",
        "print(df.head())\n",
        "\n",
        "# Dataset oluşturma\n",
        "from datasets import Dataset\n",
        "dataset = Dataset.from_pandas(df[['input_text', 'output_text']])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "5bcc017a248846f69dbe51d28db78fa3",
            "fdf360f8f1cf4a1d881046902d80c975",
            "71a963d022be4033a37bd1bee7cfb128",
            "bd24624128c44bb39221006c79eb06fa",
            "8d8824e7f970412eadf3ac372b6ca96d",
            "c2b0b9f07c6146a19d9d82b863563562",
            "32a6e61d702d417a8a97f8045fc94203",
            "ed05104ad1254b3490115bb5d031f50e",
            "4782b48138d74e33bba1f5b84999ef8e",
            "2fbb0d06ee1e4e70b62e7949399f51f0",
            "e8dd4fface4a498a8f87c66c7b4ad63f"
          ]
        },
        "id": "ugpA9E_RiHoF",
        "outputId": "9141f275-7ca7-4176-a29f-c6c9a19a548e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5bcc017a248846f69dbe51d28db78fa3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
        "import torch\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Tokenizer ve Model Yükleme\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "# Padding token ekleme\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Verileri tokenize etme fonksiyonu\n",
        "def tokenize_function(examples):\n",
        "    inputs = tokenizer(examples['input_text'], max_length=256, truncation=True, padding=\"max_length\")\n",
        "    outputs = tokenizer(examples['output_text'], max_length=256, truncation=True, padding=\"max_length\")\n",
        "    inputs[\"labels\"] = outputs[\"input_ids\"]\n",
        "    return inputs\n",
        "\n",
        "# Verileri tokenize etme\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=[\"input_text\", \"output_text\"])\n",
        "\n",
        "# Eğitim ve test seti oluşturma\n",
        "tokenized_datasets = tokenized_datasets.train_test_split(test_size=0.2)\n",
        "train_dataset = tokenized_datasets['train']\n",
        "test_dataset = tokenized_datasets['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "KAYzOfI2jk39",
        "outputId": "99245002-88a9-4c32-9962-78280cf25ddb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1000/1000 07:15, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.082900</td>\n",
              "      <td>1.055776</td>\n",
              "      <td>0.730492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.996000</td>\n",
              "      <td>0.934297</td>\n",
              "      <td>0.728790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.890400</td>\n",
              "      <td>0.865650</td>\n",
              "      <td>0.731604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.883700</td>\n",
              "      <td>0.825006</td>\n",
              "      <td>0.730708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.800500</td>\n",
              "      <td>0.807281</td>\n",
              "      <td>0.729057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.804100</td>\n",
              "      <td>0.783872</td>\n",
              "      <td>0.729486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.821400</td>\n",
              "      <td>0.758530</td>\n",
              "      <td>0.731915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.789200</td>\n",
              "      <td>0.747024</td>\n",
              "      <td>0.733157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.755400</td>\n",
              "      <td>0.739082</td>\n",
              "      <td>0.731236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.773800</td>\n",
              "      <td>0.738758</td>\n",
              "      <td>0.731106</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1000, training_loss=0.8865238862037659, metrics={'train_runtime': 435.9592, 'train_samples_per_second': 4.588, 'train_steps_per_second': 2.294, 'total_flos': 261292032000000.0, 'train_loss': 0.8865238862037659, 'epoch': 10.0})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "import pandas as pd\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
        "import evaluate\n",
        "\n",
        "\n",
        "# Eğitim argümanları\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    warmup_steps=100,\n",
        "    learning_rate=1e-5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=3,\n",
        ")\n",
        "\n",
        "# F1 skoru hesaplama fonksiyonu\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = torch.argmax(torch.tensor(logits), dim=-1).flatten().cpu().numpy()\n",
        "    labels = torch.tensor(labels).flatten().cpu().numpy()\n",
        "    f1 = f1_score(labels, predictions, average='weighted')\n",
        "    return {'f1': f1}\n",
        "\n",
        "# Trainer tanımlama\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Model eğitimi\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hb_EToeemiks",
        "outputId": "ed28b93c-15a1-40ca-ae69-1f4f0328c643"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/planlama/2trained_model/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/planlama/2trained_model/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/planlama/2trained_model/vocab.json',\n",
              " '/content/drive/MyDrive/planlama/2trained_model/merges.txt',\n",
              " '/content/drive/MyDrive/planlama/2trained_model/added_tokens.json')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Modeli kaydetme\n",
        "model_save_path = \"/content/drive/MyDrive/planlama/2trained_model\"\n",
        "\n",
        "# Modeli ve tokenizer'ı kaydetme\n",
        "model.save_pretrained(model_save_path)\n",
        "tokenizer.save_pretrained(model_save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUO90Rb9s-8z",
        "outputId": "87bc668e-771b-4855-ab19-16fe1ba3627e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Giriş: 09:00 ile 10:00 arasında toplantı yapacağım, 12:00 ile 13:00 arasında öğle yemeği yapacağım, 16:00 ile 17:00 arasında arkadaş buluşması yapacağım, 17:00 ile 19:00 arasında yemek randevusu yapacağım, 21:00 ile 22:00 arasında kitap okuma yapacağım\n",
            "Beklenen Çıkış: 09:00 - 10:00 toplantı, 12:00 - 13:00 öğle yemeği, 16:00 - 17:00 arkadaş buluşması, 17:00 - 19:00 yemek randevusu, 21:00 - 22:00 kitap okuma\n",
            "Model Çıkışı: 09:00 - 10:00 toplantı  12:00 - 13:00 öğle yemeği  16:00 - 17:00 arkadaş buluşması  17:00 - 19:00 yemek randevusu  21:00 - 22:00 kitap okuma\n",
            "F1 Skoru: 0.8333333333333334\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import re\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Model ve tokenizer yükleme\n",
        "model_save_path = \"/content/drive/MyDrive/planlama/2trained_model\"\n",
        "model = GPT2LMHeadModel.from_pretrained(model_save_path)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_save_path)\n",
        "\n",
        "# Cihaz ayarları\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def format_output(output_text):\n",
        "    formatted_output = re.sub(r'(\\d{2}:\\d{2}) ile (\\d{2}:\\d{2}) arasında', r'\\1 - \\2', output_text)\n",
        "    formatted_output = re.sub(r'yapacağım', '', formatted_output)\n",
        "    formatted_output = formatted_output.replace(',', '')\n",
        "    return formatted_output.strip()\n",
        "\n",
        "# Modelden çıktı üretme fonksiyonu\n",
        "def generate_output(input_text):\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=256, truncation=True, padding=\"max_length\")\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs, max_new_tokens=128, pad_token_id=tokenizer.eos_token_id)\n",
        "    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return format_output(output_text.strip())\n",
        "\n",
        "# F1 skoru hesaplama fonksiyonu\n",
        "def calculate_f1_score(true_output, predicted_output):\n",
        "    true_output_tokens = true_output.split()\n",
        "    predicted_output_tokens = predicted_output.split()\n",
        "\n",
        "    # Uzunlukları eşitlemek için padding yapma\n",
        "    max_len = max(len(true_output_tokens), len(predicted_output_tokens))\n",
        "    true_output_tokens += [''] * (max_len - len(true_output_tokens))\n",
        "    predicted_output_tokens += [''] * (max_len - len(predicted_output_tokens))\n",
        "\n",
        "    return f1_score(true_output_tokens, predicted_output_tokens, average='weighted')\n",
        "\n",
        "# Test girişi\n",
        "input_text = \"09:00 ile 10:00 arasında toplantı yapacağım, 12:00 ile 13:00 arasında öğle yemeği yapacağım, 16:00 ile 17:00 arasında arkadaş buluşması yapacağım, 17:00 ile 19:00 arasında yemek randevusu yapacağım, 21:00 ile 22:00 arasında kitap okuma yapacağım\"\n",
        "true_output = \"09:00 - 10:00 toplantı, 12:00 - 13:00 öğle yemeği, 16:00 - 17:00 arkadaş buluşması, 17:00 - 19:00 yemek randevusu, 21:00 - 22:00 kitap okuma\"\n",
        "\n",
        "predicted_output = generate_output(input_text)\n",
        "\n",
        "# F1 skoru hesaplama\n",
        "f1 = calculate_f1_score(true_output, predicted_output)\n",
        "\n",
        "print(\"Giriş:\", input_text)\n",
        "print(\"Beklenen Çıkış:\", true_output)\n",
        "print(\"Model Çıkışı:\", predicted_output)\n",
        "print(\"F1 Skoru:\", f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dVmdAecFwZB",
        "outputId": "4b63e363-be6b-4d16-d825-037621bc5b97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Giriş:  9:00 ile 10:00 arasi dersim var. 15:00 ile 17:00 arasi yemek yiyecegim. 22 ile 23 arası film izleyecegim\n",
            "Model Çıkışı: 9:00 - 10:00 dersim . 15:00 - 17:00 yemek yiyecegim. 22:00 - 23:00 film izleyecegim.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import re\n",
        "\n",
        "# Model ve tokenizer yükleme\n",
        "model_save_path = \"/content/drive/MyDrive/planlama/2trained_model\"\n",
        "model = GPT2LMHeadModel.from_pretrained(model_save_path)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_save_path)\n",
        "\n",
        "# Cihaz ayarları\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "def format_output(output_text):\n",
        "    # Tüm varyasyonları yakalamak için regex desenlerini genişletme\n",
        "    formatted_output = re.sub(r'(\\d{1,2}):(\\d{2}) (ile|ve|-) (\\d{1,2}):(\\d{2}) (arası|arasında)', r'\\1:\\2 - \\4:\\5', output_text, flags=re.IGNORECASE)\n",
        "    formatted_output = re.sub(r'(\\d{1,2}):(\\d{2})-(\\d{1,2}):(\\d{2})', r'\\1:\\2 - \\3:\\4', formatted_output)  # Zaman aralıklarını düzeltme\n",
        "    formatted_output = re.sub(r'(\\d{1,2}) (ile|ve|-) (\\d{1,2}) (arası|arasında)', r'\\1:00 - \\3:00', formatted_output, flags=re.IGNORECASE)\n",
        "\n",
        "    # Gereksiz kelimeleri kaldırma\n",
        "    formatted_output = re.sub(r'\\b(yapacağım|yapacagim|var|olacak|yapmak)\\b', '', formatted_output, flags=re.IGNORECASE)\n",
        "\n",
        "    # Noktalama işaretlerini düzenleme\n",
        "    formatted_output = formatted_output.replace(',', ' ').replace('  ', ' ').strip()\n",
        "\n",
        "    # Sonundaki gereksiz karakterleri kaldırma\n",
        "    formatted_output = re.sub(r'0+$', '', formatted_output)\n",
        "\n",
        "    # Cümlenin sonuna noktaları ekleyerek düzenleme\n",
        "    if formatted_output and formatted_output[-1] != '.':\n",
        "        formatted_output += '.'\n",
        "\n",
        "    return formatted_output.strip()\n",
        "\n",
        "# Modelden çıktı üretme fonksiyonu\n",
        "def generate_output(input_text):\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=256, truncation=True, padding=\"max_length\")\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs, max_new_tokens=128, pad_token_id=tokenizer.eos_token_id)\n",
        "    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return format_output(output_text.strip())\n",
        "\n",
        "# Test fonksiyonu\n",
        "def test_model():\n",
        "    input_text = input(\"Giriş: \")\n",
        "    predicted_output = generate_output(input_text)\n",
        "    print(\"Model Çıkışı:\", predicted_output)\n",
        "\n",
        "# Modeli test etme\n",
        "test_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YSe_hcptgVc",
        "outputId": "d5807664-f778-4dd6-f294-0b23a9a15d98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Collecting flask-cors\n",
            "  Downloading Flask_Cors-4.0.1-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.1.6-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: pyngrok, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, flask-cors\n",
            "Successfully installed flask-cors-4.0.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pyngrok-7.1.6\n"
          ]
        }
      ],
      "source": [
        "!pip install flask flask-cors transformers torch pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_HcXDih6dTQ",
        "outputId": "6cdaf8bb-b006-43e0-8684-2fa811ac4b93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.1.6-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.1.6\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Collecting flask-cors\n",
            "  Downloading Flask_Cors-4.0.1-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.10/dist-packages (from flask-cors) (2.2.5)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask-cors) (3.0.3)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask-cors) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask-cors) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask-cors) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.9->flask-cors) (2.1.5)\n",
            "Installing collected packages: flask-cors\n",
            "Successfully installed flask-cors-4.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok\n",
        "!ngrok authtoken 2hFh039c1mHorUiI6urdqACI8M9_5y1JwajcHDmyudmRduovu\n",
        "!pip install flask-cors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gd1stmgDzczP"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Ngrok auth token'ınızı buraya ekleyin\n",
        "ngrok.set_auth_token(\"2hFh039c1mHorUiI6urdqACI8M9_5y1JwajcHDmyudmRduovu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nuwy0IBjzfdD",
        "outputId": "0c22d2b5-7ff7-4070-e878-49d759f7424c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ngrok Tunnel URL: NgrokTunnel: \"https://573a-35-185-231-208.ngrok-free.app\" -> \"http://localhost:5000\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [13/Jun/2024 10:25:31] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [13/Jun/2024 10:25:49] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [13/Jun/2024 10:26:17] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [13/Jun/2024 10:26:28] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [13/Jun/2024 10:26:56] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [13/Jun/2024 10:29:47] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [13/Jun/2024 10:30:05] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [13/Jun/2024 10:30:26] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [13/Jun/2024 10:30:44] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [13/Jun/2024 10:31:07] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [13/Jun/2024 10:49:11] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [13/Jun/2024 10:49:50] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [13/Jun/2024 10:50:12] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import re\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from pyngrok import ngrok\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "# Model ve tokenizer yükleme\n",
        "model_save_path = \"/content/drive/MyDrive/planlama/2trained_model\"\n",
        "model = GPT2LMHeadModel.from_pretrained(model_save_path)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_save_path)\n",
        "\n",
        "# Cihaz ayarları\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "def format_output(output_text):\n",
        "    # İstenmeyen işaretleri kaldır\n",
        "    output_text = output_text.replace('------', '')\n",
        "\n",
        "    formatted_output = re.sub(r'(\\d{1,2}):(\\d{2}) (ile|ve|-) (\\d{1,2}):(\\d{2}) (arası|arasında|arasinda|arasi)', r'\\1:\\2 - \\4:\\5', output_text, flags=re.IGNORECASE)\n",
        "    formatted_output = re.sub(r'(\\d{1,2}):(\\d{2})-(\\d{1,2}):(\\d{2})', r'\\1:\\2 - \\3:\\4', formatted_output)  # Zaman aralıklarını düzeltme\n",
        "    formatted_output = re.sub(r'(\\d{1,2}) (ile|ve|-) (\\d{1,2}) (arası|arasında)', r'\\1:00 - \\3:00', formatted_output, flags=re.IGNORECASE)\n",
        "    formatted_output = re.sub(r'\\b(yapacağım|yapacagim|var|olacak|yapmak|gidecegim|izleyecegim|oturacagım|icecegim|edecegim|yiyecegim|uygulayacagim|uyuyacagim|kalkacagim|calisacagim)\\b', '', formatted_output, flags=re.IGNORECASE)\n",
        "    formatted_output = formatted_output.replace(',', ' ').replace('  ', ' ').strip()\n",
        "    formatted_output = re.sub(r'0+$', '', formatted_output)\n",
        "    if formatted_output and formatted_output[-1] != '.':\n",
        "        formatted_output += '.'\n",
        "    return formatted_output.strip()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Modelden çıktı üretme fonksiyonu\n",
        "def generate_output(input_text):\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=256, truncation=True, padding=\"max_length\")\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs, max_new_tokens=128, pad_token_id=tokenizer.eos_token_id)\n",
        "    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return format_output(output_text.strip())\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    data = request.get_json()\n",
        "    input_text = data['input_text']\n",
        "    output_text = generate_output(input_text)\n",
        "    return jsonify({'output_text': output_text})\n",
        "\n",
        "def start_ngrok():\n",
        "    url = ngrok.connect(5000)\n",
        "    print(f'Ngrok Tunnel URL: {url}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        executor.submit(start_ngrok)\n",
        "        app.run(port=5000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ikq44M4e1Y0K"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPrw59WtWAaKCEeXHfacs40",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2fbb0d06ee1e4e70b62e7949399f51f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32a6e61d702d417a8a97f8045fc94203": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4782b48138d74e33bba1f5b84999ef8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5bcc017a248846f69dbe51d28db78fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fdf360f8f1cf4a1d881046902d80c975",
              "IPY_MODEL_71a963d022be4033a37bd1bee7cfb128",
              "IPY_MODEL_bd24624128c44bb39221006c79eb06fa"
            ],
            "layout": "IPY_MODEL_8d8824e7f970412eadf3ac372b6ca96d"
          }
        },
        "71a963d022be4033a37bd1bee7cfb128": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed05104ad1254b3490115bb5d031f50e",
            "max": 250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4782b48138d74e33bba1f5b84999ef8e",
            "value": 250
          }
        },
        "8d8824e7f970412eadf3ac372b6ca96d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd24624128c44bb39221006c79eb06fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fbb0d06ee1e4e70b62e7949399f51f0",
            "placeholder": "​",
            "style": "IPY_MODEL_e8dd4fface4a498a8f87c66c7b4ad63f",
            "value": " 250/250 [00:01&lt;00:00, 189.05 examples/s]"
          }
        },
        "c2b0b9f07c6146a19d9d82b863563562": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8dd4fface4a498a8f87c66c7b4ad63f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed05104ad1254b3490115bb5d031f50e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdf360f8f1cf4a1d881046902d80c975": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2b0b9f07c6146a19d9d82b863563562",
            "placeholder": "​",
            "style": "IPY_MODEL_32a6e61d702d417a8a97f8045fc94203",
            "value": "Map: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}